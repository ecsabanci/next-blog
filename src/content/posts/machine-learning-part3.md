---
title: "Makine Ã–ÄŸrenmesi Part-3"
date: "2024-03-30"
excerpt: "YanlÄ±lÄ±k - Varyans DeÄŸiÅŸ TokuÅŸu (Bias-Variance Tradeoff)"
category: "Machine Learning, Data Science"
---

ğŸ§¡ Merhaba! [Part-2 yazÄ±mda](/posts/machine-learning-part2) makine Ã¶ÄŸrenmesi tÃ¼rlerine deÄŸinmiÅŸtim. Bu yazÄ±da YanlÄ±lÄ±k - Varyans DeÄŸiÅŸ TokuÅŸu (Bias-Variance Tradeoff)'u ele alacaÄŸÄ±m.

ğŸ’¡ Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± daha iyi anlamak ve verileriniz Ã¼zerinde daha iyi performans elde etmek iÃ§in bunu nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± keÅŸfedeceksiniz.

*Ä°yi okumalar!*

*Tahmin modellerini tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±zda, tahmin hatalarÄ± Ã¶nemsediÄŸimiz iki ana alt bileÅŸene ayrÄ±labilir: "bias"tan kaynaklanan hata ve "varyans"tan kaynaklanan hata.*

## 1. YanlÄ±lÄ±k HatasÄ± (Bias Error)

Bias â˜ modelin Ã¶ÄŸrenmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ± fonksiyon hakkÄ±nda yaptÄ±ÄŸÄ± varsayÄ±mdÄ±r.

Genel olarak doÄŸrusal algoritmalarÄ±n yÃ¼ksek bir yanlÄ±lÄ±ÄŸÄ± vardÄ±r, bu da Ã¶ÄŸrenilmesini hÄ±zlÄ± ve anlaÅŸÄ±lmasÄ±nÄ± kolaylaÅŸtÄ±rÄ±r ancak genellikle daha az esnektir.

Bias, bu modellerin tahminlerinin doÄŸru deÄŸerden ne kadar uzakta olduÄŸunu Ã¶lÃ§er.

- **DÃ¼ÅŸÃ¼k YanlÄ±lÄ±k (Low-Bias)**: Modelin, hedef fonksiyonu belirlerken daha az varsayÄ±ma dayanmasÄ± anlamÄ±na gelir.
  â˜ Decision Trees, K-Nearest Neighbors, Support Vector Machines

- **YÃ¼ksek YanlÄ±lÄ±k (High-Bias)**: Modelin, hedef fonksiyonu belirlerken daha fazla varsayÄ±ma dayanmasÄ± anlamÄ±na gelir.
  â˜ Linear Regression, Linear Discriminant Analysis and Logistic Regression

## 2. Varyans HatasÄ± (Variance Error)

Varyans â˜ farklÄ± eÄŸitim verileri kullanÄ±ldÄ±ÄŸÄ±nda hedef fonksiyonun tahmininin deÄŸiÅŸeceÄŸi miktardÄ±r.

Hedef fonksiyon, bir makine Ã¶ÄŸrenimi algoritmasÄ± tarafÄ±ndan eÄŸitim verilerinden tahmin edilir, bu nedenle algoritmanÄ±n bir miktar farklÄ±lÄ±ÄŸa sahip olmasÄ±nÄ± beklemeliyiz.

- **DÃ¼ÅŸÃ¼k Varyans**: Model, eÄŸitim verilerindeki kÃ¼Ã§Ã¼k deÄŸiÅŸikliklerden Ã§ok az etkilenerek, tutarlÄ± tahminler sunar.
  â˜ Linear Regression, Linear Discriminant Analysis and Logistic Regression.

- **YÃ¼ksek Varyans**: EÄŸitim veri setindeki deÄŸiÅŸikliklerle modelin tahminlerinde bÃ¼yÃ¼k dalgalanmalar meydana gelir.
  â˜ Decision Trees, K-Nearest Neighbors and Support Vector Machines.

*ğŸ¹ Hedefimiz*,  
ğŸ”½ hem dÃ¼ÅŸÃ¼k varyans,  
ğŸ”½ hem de dÃ¼ÅŸÃ¼k yanlÄ±lÄ±k gÃ¶steren bir model geliÅŸtirmektir.

Bu ideal durum, modelin eÄŸitim verilerini etkin bir ÅŸekilde Ã¶ÄŸrendiÄŸini ve aynÄ± zamanda yeni verilere karÅŸÄ± esnek kaldÄ±ÄŸÄ±nÄ± gÃ¶sterir. Bu dengeli yaklaÅŸÄ±m, modelin eÄŸitim verilerine aÅŸÄ±rÄ± uyum saÄŸlamasÄ±na (overfitting) ve yetersiz kalmasÄ±na (underfitting) izin vermez, bÃ¶ylece model gerÃ§ek durumlara karÅŸÄ± gÃ¼venilir tahminler sunabilir.

ğŸ’¡ En iyi model veri setinin genel yapÄ±sÄ±nÄ± yakalayan ve yeni verilere iyi genelleme yapabilen bir yapÄ±dadÄ±r!

Ã–rneÄŸin ğŸ‘‡ğŸ»

## GÃ¶rselin AÃ§Ä±klamasÄ±

Mavi yÄ±ldÄ±zlar bir sÄ±nÄ±fÄ±, kÄ±rmÄ±zÄ± Ã§emberler ise diÄŸer bir sÄ±nÄ±fÄ± temsil eder ve siyah Ã§izgi modelin tahmin Ã§izgisini gÃ¶sterir.

**a. Underfitting durumu (DÃ¼ÅŸÃ¼k uyum):**
- DÃ¼ÅŸÃ¼k model karmaÅŸÄ±klÄ±ÄŸÄ± olarak isimlendirilir.
- High Bias ve Low Variance ile oluÅŸur.
- EÄŸitim ve test hatasÄ± Ã§ok yÃ¼ksek. Modelin train setini yeterince iyi temsil edemediÄŸini gÃ¶sterir.

**b. Optimal model:**
- Modelin tahmin Ã§izgisi her iki sÄ±nÄ±fÄ± da oldukÃ§a iyi bir ÅŸekilde ayÄ±rÄ±r. Bu, modelin veri setinin yapÄ±sal Ã¶zelliklerini yeterli dÃ¼zeyde Ã¶ÄŸrendiÄŸini ve iyi bir genelleme yapabildiÄŸini gÃ¶sterir.
- Model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n ve performansÄ±nÄ±n optimal noktada olduÄŸunu gÃ¶sterir.

**c. Overfitting (AÅŸÄ±rÄ± uyum):**
- YÃ¼ksek model karmaÅŸÄ±klÄ±ÄŸÄ± olarak isimlendirilir.
- Siyah Ã§izgi, veri noktalarÄ±na mÃ¼kemmel uyum saÄŸlamaya Ã§alÄ±ÅŸÄ±rken Ã§ok fazla kÄ±vrÄ±m iÃ§erir, bu da modelin veri setindeki gÃ¼rÃ¼ltÃ¼yÃ¼ de Ã¶ÄŸrenmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterir. Yani **_model, verideki Ã¶rÃ¼ntÃ¼yÃ¼ ezberler._**
- EÄŸitim hatasÄ± dÃ¼ÅŸerken, test hatasÄ± artar.

Ã–zetle,

Makine Ã¶ÄŸrenmesi modellerinde Bias-Variance Tradeoff, modelin hem eÄŸitim verileri Ã¼zerindeki performansÄ±nÄ± hem de genelleÅŸtirme yeteneÄŸini optimize etmek iÃ§in denge saÄŸlamayÄ± hedefler.  
Ä°deal bir model, veri setinin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± ve yapÄ±sal Ã¶zelliklerini doÄŸru bir ÅŸekilde yakalayarak yeni verilere karÅŸÄ± saÄŸlam ve gÃ¼venilir tahminlerde bulunabilir.  
Modelin ne kadar karmaÅŸÄ±k olmasÄ± gerektiÄŸini belirlemek, uygulamanÄ±n gereksinimlerine ve kullanÄ±lacak veri setine baÄŸlÄ±dÄ±r. Bu nedenle, model seÃ§imi yaparken yanlÄ±lÄ±k ve varyans arasÄ±ndaki iliÅŸkiyi dikkate almak, aÅŸÄ±rÄ± uyum (overfitting) ve yetersiz uyum (underfitting) gibi istenmeyen durumlarÄ±n Ã¶nÃ¼ne geÃ§ilmesinde kritik bir role sahiptir.  
Makine Ã¶ÄŸrenmesi projelerinde baÅŸarÄ±ya ulaÅŸmak iÃ§in, modellerin bu iki temel unsuru dengeli bir ÅŸekilde ele almasÄ±nÄ± saÄŸlamak ve bu sayede veri setinin genel yapÄ±sÄ±nÄ± en iyi ÅŸekilde modellemek gerekir.

OkuduÄŸunuz iÃ§in teÅŸekkÃ¼r ederim. âœ¨

Kaynaklar:

1. [Vijayakumar, Sethu](https://en.wikipedia.org/wiki/Sethu_Vijayakumar) (2007). ["The Biasâ€“Variance Tradeoff"](http://www.inf.ed.ac.uk/teaching/courses/mlsc/Notes/Lecture4/BiasVariance.pdf) (PDF). [University of Edinburgh](https://en.wikipedia.org/wiki/University_of_Edinburgh). Retrieved 19 August 2014.

2. Fortmann-Roe, Scott (2012). ["Understanding the Biasâ€“Variance Tradeoff"](http://scott.fortmann-roe.com/docs/BiasVariance.html).

3. Neal, Brady; Mittal, Sarthak; Baratin, Aristide; Tantia, Vinayak; Scicluna, Matthew; Lacoste-Julien, Simon; Mitliagkas, Ioannis (2019). [*A Modern Take on the Bias-Variance Tradeoff in Neural Networks*](https://openreview.net/forum?id=HkgmzhC5F7). International Conference on Learning Representations (ICLR) 2019. 